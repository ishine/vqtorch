<html>

<head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

    <!--
  <script src="./resources/jsapi" type="text/javascript"></script>
  <script type="text/javascript" async>google.load("jquery", "1.3.2");</script>
 -->

<!-- @font-face {
font-family: 'Avenir Book';
src: url("./fonts/Avenir_Book.ttf");
/* File to be stored at your site */
} -->

    <style type="text/css">

        body {
            font-family: "Avenir Book", "HelveticaNeue-Light", "Helvetica Neue Light", "Helvetica Neue", Helvetica, Arial, "Lucida Grande", sans-serif;
            font-weight: 300;
            font-size: 14px;
            margin-left: auto;
            margin-right: auto;
            width: 800px;
        }

        h1 {
            font-weight: 300;
        }

        h2 {
            font-weight: 300;
        }

        p {
            font-weight: 300;
            line-height: 1.4;
        }

        code {
            font-size: 0.8rem;
            margin: 0 0.2rem;
            padding: 0.5rem 0.8rem;
            white-space: nowrap;
            background: #efefef;
            border: 1px solid #d3d3d3;
            color: #000000;
            border-radius: 3px;
        }

        pre>code {
            display: block;
            white-space: pre;
            line-height: 1.5;
            padding: 0;
            margin: 0;
        }

        pre.prettyprint>code {
            border: none;
        }



        .disclaimerbox {
            background-color: #eee;
            border: 1px solid #eeeeee;
            border-radius: 10px;
            -moz-border-radius: 10px;
            -webkit-border-radius: 10px;
            padding: 20px;
        }

        video.header-vid {
            height: 140px;
            border: 1px solid black;
            border-radius: 10px;
            -moz-border-radius: 10px;
            -webkit-border-radius: 10px;
        }

        img.header-img {
            height: 140px;
            border: 1px solid black;
            border-radius: 10px;
            -moz-border-radius: 10px;
            -webkit-border-radius: 10px;
        }

        img.rounded {
            border: 0px solid #eeeeee;
            border-radius: 10px;
            -moz-border-radius: 10px;
            -webkit-border-radius: 10px;

        }

        a:link,
        a:visited {
            color: #1367a7;
            text-decoration: none;
        }

        a:hover {
            color: #208799;
        }

        td.dl-link {
            height: 160px;
            text-align: center;
            font-size: 22px;
        }

        .layered-paper-big {
            /* modified from: http://css-tricks.com/snippets/css/layered-paper/ */
            box-shadow:
                0px 0px 1px 1px rgba(0, 0, 0, 0.35),
                /* The top layer shadow */
                5px 5px 0 0px #fff,
                /* The second layer */
                5px 5px 1px 1px rgba(0, 0, 0, 0.35),
                /* The second layer shadow */
                10px 10px 0 0px #fff,
                /* The third layer */
                10px 10px 1px 1px rgba(0, 0, 0, 0.35),
                /* The third layer shadow */
                15px 15px 0 0px #fff,
                /* The fourth layer */
                15px 15px 1px 1px rgba(0, 0, 0, 0.35),
                /* The fourth layer shadow */
                20px 20px 0 0px #fff,
                /* The fifth layer */
                20px 20px 1px 1px rgba(0, 0, 0, 0.35),
                /* The fifth layer shadow */
                25px 25px 0 0px #fff,
                /* The fifth layer */
                25px 25px 1px 1px rgba(0, 0, 0, 0.35);
            /* The fifth layer shadow */
            margin-left: 10px;
            margin-right: 45px;
        }


        .layered-paper {
            /* modified from: http://css-tricks.com/snippets/css/layered-paper/ */
            box-shadow:
                0px 0px 1px 1px rgba(0, 0, 0, 0.35),
                /* The top layer shadow */
                5px 5px 0 0px #fff,
                /* The second layer */
                5px 5px 1px 1px rgba(0, 0, 0, 0.35),
                /* The second layer shadow */
                10px 10px 0 0px #fff,
                /* The third layer */
                10px 10px 1px 1px rgba(0, 0, 0, 0.35);
            /* The third layer shadow */
            margin-top: 5px;
            margin-left: 10px;
            margin-right: 30px;
            margin-bottom: 5px;
        }

        .vert-cent {
            position: relative;
            top: 50%;
            transform: translateY(-50%);
        }

        hr {
            border: 0;
            height: 1px;
            background-image: linear-gradient(to right, rgba(0, 0, 0, 0), rgba(0, 0, 0, 0.75), rgba(0, 0, 0, 0));
        }
    </style>



    <title>VQ-STE++</title>
</head>

<body>
    <br>
    <center>
        <span style="font-size:26px">Straightening Out the Straight-Through Estimator:<br>
        Overcoming Optimization Challenges in Vector Quantized Networks</span><br><br><br>
    </center>
    <table align="center" width="800px">
        <tbody>
            <tr>
                <td align="center" width="160px">
                    <center>
                        <span style="font-size:16px"><a href="http://minyounghuh.com">Minyoung
                                Huh</a><sup>1</sup></span>
                    </center>
                </td>
                <td align="center" width="160px">
                    <center>
                        <span style="font-size:16px"><a
                                href="https://scholar.google.com/citations?user=7N-ethYAAAAJ&hl=en">Brian
                                Cheung</a><sup>1 2</sup></span>
                    </center>
                </td>
                <td align="center" width="160px">
                    <center>
                        <span style="font-size:16px"><a href="https://people.csail.mit.edu/pulkitag/">Pulkit
                                Agrawal</a><sup>1</sup></span>
                    </center>
                </td>
                <td align="center" width="160px">
                    <center>
                        <span style="font-size:16px"><a href="http://web.mit.edu/phillipi/">Phillip
                                Isola</a><sup>1</sup></span>
                    </center>
            </tr>

        </tbody>
    </table><br>

    <table align="center" width="700px">
        <tbody>
            <tr>
                <td align="center" width="50px">
                    <center>
                        <span style="font-size:16px"></span>
                    </center>
                </td>
                <td align="center" width="250px">
                    <center>
                        <span style="font-size:16px"><sup>1</sup>MIT CSAIL</span>
                    </center>
                </td>
                <td align="center" width="250px">
                    <center>
                        <span style="font-size:16px"><sup>2</sup>MIT BCS</span>
                    </center>
                </td>
                <td align="center" width="50px">
                    <center>
                        <span style="font-size:16px"></span>
                    </center>
                </td>
            </tr>
        </tbody>
    </table>
    <table align="center" width="700px">
        <tbody>
            <tr>
                <td align="center" width="200px">
                    <center>
                        <br>
                        <span style="font-size:20px">
                            <a href=..>code (coming soon)</a>
                        </span>
                    </center>
                </td>

                <td align="center" width="200px">
                    <center>
                        <br>
                        <span style="font-size:20px">
                            <a href="./assets/draft_050523.pdf">paper</a>
                            <br />
                        </span>
                    </center>
                </td>

                <td align="center" width="200px">
                    <center>
                        <br>
                        <span style="font-size:20px">
                            <a href="./cite.txt">cite</a>
                        </span>
                    </center>
                </td>

            </tr>
        </tbody>
    </table>
    <br />
    <hr>
    <center>
        <h2>
            Abstract
        </h2>
    </center>
    <p>
        <left>
            This work examines the challenges of training neural networks using vector quantization using straight-through
            estimation. We find that a primary cause of training instability is the discrepancy between the model embedding and the
            code-vector distribution. We identify the factors that contribute to this issue, including the codebook gradient
            sparsity and the asymmetric nature of the commitment loss, which leads to misaligned code-vector assignments. We propose
            to address this issue via affine re-parameterization of the code vectors. Additionally, we introduce an alternating
            optimization to reduce the gradient error introduced by the straight-through estimation. Moreover, we propose an
            improvement to the commitment loss to ensure better alignment between the codebook representation and the model
            embedding. These optimization methods improve the mathematical approximation of the straight-through estimation and,
            ultimately, the model performance. We demonstrate the effectiveness of our methods on several common model
            architectures, such as AlexNet, ResNet, and ViT, across various tasks, including image classification and generative
            modeling.
        </left>
    </p>

    <p style="background: #fff3b0;"> <center style="background: #fff3b0;"> Simplify and improve your existing VQ model performance with our <a href="https://github.com/minyoungg/vqtorch"><b>VQTorch library</b></a> </center> </p>

    <br>

    <hr>
    <center>
        <h2> Results </h2>
    </center>
    <br/>

    <p>
      We observe that a primary cause of training instability is attributed to a shift in the embedding distribution.
      As the embedding distribution P shifts, it misaligns with the codebook distribution C. The <b>misalignment occurs due to the sparse, delayed, and inaccurate straight-through estimation </b> used to update the codebook.
      The set of assigned code-vectors Q continuously shrinks as models are trained for longer. This phenomenon is referred to as "index collapse".
    </p>
    <br />
    <p><center>
      <img class="rounded" src="./assets/drift.png" width="500px">
    </center></p>

    <br />
    <p>
      To reduce this divergence, we propose an <b>affine re-parameterization</b> of the code-vectors that can better match the moments of the embedding representation.
      An affine re-parameterization with shared parameters ensures that the code-vectors that do not have an assignment still receive gradients.
      The affine parameters can either be learned or computed using running statistics. This can be easily extended beyond a single affine parameter to a group.
    </p>
    <br />
    <p><center><img src="./assets/svg.svg" width="200px"></center></p>
    <br />
    <p>
      We can directly observe the effect of affine re-parameterization by visualizing the P, C, and Q using a low-dimensional projection.
    </p>
    <br />
    <p><img class="rounded" src="./assets/divergence.png" width="800px"></p>
    <br />

    <p>
      The inaccuracy of the straight-through-estimator is proportional to the error in the commitment loss -- the divergence between P and Q.
      In order to reduce the inaccurate estimation, we use a coordinate descent style optimization approach in which we first reduce the commitment loss before minimizing the task loss (alternated optimization).
    </p>
    <p>
      Not only is the straight-through estimation inaccurate we find that the representation of the codebook is always delayed by a single iteration, resulting in a slowdown in convergence.
      We remove the delay in the codebook representation by further updating the codebook in the direction that minimizes task loss (synchronized commitment loss).
    </p>
    <p>
      A toy example below shows how these changes affect the optimization trajectory.
    </p>
    <br />
    <p><img class="rounded" src="./assets/opt_vis.png" width="800px"></p>

    <br />
    <p>
      Combining our proposed methods above, we get a consistent improvement in various VQ-based tasks, including generative modeling and image classification.
      The figure below is generated using MaskGIT* framework for CelebA. OPT refers to both alternating optimization + synchronized commitment loss.
      Refer to the main paper for additional results, including image classification.
    </p>
    <br />

    <p><center><img class="rounded" src="./assets/maskgit_fid.png" width="300px"><img class="rounded" src="./assets/maskgit_rfid.png" width="300px" /></center></p>
    <p>
      (*Note: MaskGIT was trained without perceptual and discriminative loss to reduce training and memory overhead.)
    </p>

    <br>
    <hr>
    <center>
        <h2> Try our PyTorch code </h2>
    </center>
    Install our code <a href="https://github.com/minyoungg/vqtorch"> [<b>github</b>] </a>
    <pre><code>
      <font color="00509d">>>></font> <font color="1a936f">git clone</font> https://github.com/minyoungg/vqtorch
      <font color="00509d">>>></font> <font color="1a936f">cd</font> vqtorch
      <font color="00509d">>>></font> <font color="1a936f">pip install</font> -e .
      </code></pre>

    Integrate to your existing PyTorch code base.
    <pre><code>
        <font color="ef476f">import</font> torch
        <font color="ef476f">from</font> vqtorch.nn <font color="ef476f">import</font> VectorQuant

        <font color=7F8C8D># create VQ layer </font>
        vq_layer = <font color="118ab2">VectorQuant</font>(
                        <font color=#F39C12>feature_size</font>=32,    <font color=7F8C8D># feature dimension corresponding to the vectors</font>
                        <font color=#F39C12>num_codes=</font>1024,     <font color=7F8C8D># number of codebook vectors</font>
                        <font color=#F39C12>beta</font>=0.98,          <font color=7F8C8D># (default: 0.95) commitment trade-off</font>
                        <font color=#F39C12>kmeans_init</font>=True,   <font color=7F8C8D># (default: False) whether to use kmeans++ init</font>
                        <font color=#F39C12>norm</font>=None,          <font color=7F8C8D># (default: None) normalization for input vector</font>
                        <font color=#F39C12>cb_norm</font>=None,       <font color=7F8C8D># (default: None) normalization for codebook vectors</font>
                        <font color=#F39C12>affine_lr</font>=10.0,     <font color=7F8C8D># (default: 0.0) lr scale for affine parameters</font>
                        <font color=#F39C12>sync_nu</font>=0.2,        <font color=7F8C8D># (default: 0.0) codebook synchronization contribution</font>
                        <font color=#F39C12>replace_freq</font>=20,    <font color=7F8C8D># (default: 0) frequency to replace dead codes</font>
                        <font color=#F39C12>dim</font>=-1              <font color=7F8C8D># (default: -1) dimension to be quantized</font>
                        ).cuda()

        <font color=7F8C8D># when using `kmeans_init`, a warmup is recommended </font>
        <font color="AF7AC5">with</font> torch.no_grad():
            z_e = torch.randn(1, 32, 32, 3).cuda()
            vq_layer(z_e)

        <font color=7F8C8D># standard forward pass </font>
        z_q, vq_dict = vq_layer(z_e) # equivalent to above

        <font color=2E86C1>print</font>(z_q.shape)
        <font color="00509d">>>></font> (1, 64, 64, 32)

    </code></pre>


    <br>
    <hr>
    <center>
        <h2> Acknowledgements </h2>
    </center>
    <p> Minyoung Huh would like to thank his lab members for helpful feedbacks.
        <!-- Brian Cheung is funded by an MIT BCS Fellowship. -->
        <br><br>

        <br><br>
        <a href="https://richzhang.github.io/colorization/">Website template edited from Colorful Colorization</a>.
    </p>
    <br>

    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-70157890-3"></script>
    <script>
        window.dataLayer = window.dataLayer || [];
        function gtag() { dataLayer.push(arguments); }
        gtag('js', new Date());

        gtag('config', 'UA-70157890-3');
    </script>


</body>

</html>
